import ray
import asyncio
import copy
import time
import logging
import uuid
import os
import json
from typing import List, Dict, Set, Optional
from trajectory_runner import TrajectoryRunnerActor, ResourceExhaustedException
from log_config import setup_logging
from datetime import datetime

# è®¾ç½®ç»Ÿä¸€çš„æ—¥å¿—ç³»ç»Ÿ
setup_logging()
logger = logging.getLogger(__name__)

class AgentCoordinator:

    def __init__(self, coordinator_cfg):
        self.max_concurrent_envs = coordinator_cfg.max_concurrent_envs # æœ€å¤§å¹¶å‘envæ•°é‡
        self.active_tasks: Set[ray.ObjectRef] = set()  # è·Ÿè¸ªæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡
        self.task_queue = asyncio.Queue()  # ç§»é™¤é˜Ÿåˆ—å¤§å°é™åˆ¶
        self.task_trace_map: Dict[ray.ObjectRef, str] = {}  # ä»»åŠ¡å¼•ç”¨åˆ°trace_idçš„æ˜ å°„
        self.poll_count = 0  # è·Ÿè¸ªå·²ç»è·å–ä»»åŠ¡çš„æ¬¡æ•°
        self.max_task_queue_size = coordinator_cfg.max_task_queue_size # æœ€å¤šä»task_loaderè·å–ä»»åŠ¡çš„æ¬¡æ•°
        self.rollout_n = getattr(coordinator_cfg, 'rollout_n', 1)  # æ¯ä¸ªä»»åŠ¡é‡å¤rolloutçš„æ¬¡æ•°ï¼Œé»˜è®¤ä¸º1
        self.dynamic_rollout = getattr(coordinator_cfg, 'dynamic_rollout', False)  # æ˜¯å¦å¯ç”¨åŠ¨æ€rollout_n
        
        # ç¯å¢ƒæ¸…ç†ç›¸å…³
        self.env_cleanup_interval = getattr(coordinator_cfg, 'env_cleanup_interval', 10)  # ç¯å¢ƒæ¸…ç†é—´éš”ï¼ˆç§’ï¼‰
        self.env_cleanup_timeout = getattr(coordinator_cfg, 'env_cleanup_timeout', 300)  # ç¯å¢ƒè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤5åˆ†é’Ÿï¼‰
        self.last_env_cleanup_time = 0  # ä¸Šæ¬¡æ¸…ç†ç¯å¢ƒçš„æ—¶é—´
        self.active_service_ids: Set[str] = set()  # è·Ÿè¸ªæ´»è·ƒçš„service_id
        self.task_to_service_map: Dict[ray.ObjectRef, str] = {}  # ä»»åŠ¡å¼•ç”¨åˆ°service_idçš„æ˜ å°„
        self.task_to_actor_map: Dict[ray.ObjectRef, ray.actor.ActorHandle] = {}  # ä»»åŠ¡å¼•ç”¨åˆ°Actorçš„æ˜ å°„
        
        # ä¼˜é›…é€€å‡ºæ§åˆ¶
        self.should_graceful_exit = False  # ä¼˜é›…é€€å‡ºæ ‡å¿—
        self.exit_reason = ""  # é€€å‡ºåŸå› 
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_started': 0,
            'total_completed': 0,
            'total_failed': 0,
            'start_time': time.time()
        }
        
        logger.info(f"AgentCoordinatoråˆå§‹åŒ– - æœ€å¤§å¹¶å‘ç¯å¢ƒæ•°: {self.max_concurrent_envs}, æœ€å¤šå¡«å……ä»»åŠ¡: {self.max_task_queue_size} æ¬¡, rollout_n: {self.rollout_n}")
        logger.info(f"ç¯å¢ƒæ¸…ç†é…ç½® - æ¸…ç†é—´éš”: {self.env_cleanup_interval}ç§’, æ¸…ç†è¶…æ—¶: {self.env_cleanup_timeout}ç§’")
        
        # è®¾ç½®å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨æ¥æ•è·æœªå¤„ç†çš„å¼‚å¸¸
        self._setup_exception_handler()

    def _setup_exception_handler(self):
        """è®¾ç½®å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨"""
        def exception_handler(loop, context):
            exception = context.get('exception')
            if exception:
                # æ£€æŸ¥æ˜¯å¦æ˜¯Rayä»»åŠ¡é”™è¯¯
                if "RayTaskError" in str(type(exception)) or "Failed to get screenshot" in str(exception):
                    # å®Œå…¨é™é»˜Rayä»»åŠ¡é”™è¯¯ï¼Œå› ä¸ºè¿™äº›å·²ç»åœ¨_track_task_completionä¸­å¤„ç†
                    logger.debug(f"æ•è·åˆ°Rayä»»åŠ¡å¼‚å¸¸ï¼ˆé¢„æœŸè¡Œä¸ºï¼Œå·²å¤„ç†ï¼‰")
                else:
                    logger.error(f"æ•è·åˆ°æœªå¤„ç†çš„å¼‚æ­¥å¼‚å¸¸: {exception}")
                    logger.error(f"å¼‚å¸¸ä¸Šä¸‹æ–‡: {context}")
            else:
                logger.error(f"æ•è·åˆ°æœªå¤„ç†çš„å¼‚æ­¥é”™è¯¯: {context}")
        
        # åªæœ‰åœ¨å½“å‰æ²¡æœ‰event loopæ—¶æ‰è®¾ç½®
        try:
            loop = asyncio.get_running_loop()
            loop.set_exception_handler(exception_handler)
            logger.info("å·²è®¾ç½®å¼‚æ­¥å¼‚å¸¸å¤„ç†å™¨")
        except RuntimeError:
            # æ²¡æœ‰è¿è¡Œä¸­çš„event loopï¼Œç¨åä¼šè®¾ç½®
            logger.debug("æš‚æ—¶æ— æ³•è®¾ç½®å¼‚å¸¸å¤„ç†å™¨ï¼Œå°†åœ¨event loopå¯åŠ¨æ—¶è®¾ç½®")

    def _generate_trace_id(self) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„trace_id"""
        return f"trace-{uuid.uuid4().hex[:12]}-{int(time.time())}"
    

    
    async def _cleanup_orphaned_environments(self, runner_cfg):
        """æ¸…ç†å­¤ç«‹çš„ç¯å¢ƒå®ä¾‹"""
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†ç¯å¢ƒ
            current_time = time.time()
            time_since_last_cleanup = current_time - self.last_env_cleanup_time
            logger.info(f"ç¯å¢ƒæ¸…ç†æ£€æŸ¥ - è·ç¦»ä¸Šæ¬¡æ¸…ç†: {time_since_last_cleanup:.1f}ç§’, æ¸…ç†é—´éš”: {self.env_cleanup_interval}ç§’")
            
            if time_since_last_cleanup < self.env_cleanup_interval:
                logger.info(f"è·³è¿‡ç¯å¢ƒæ¸…ç† - è¿˜æ²¡åˆ°æ¸…ç†æ—¶é—´ ({time_since_last_cleanup:.1f}s < {self.env_cleanup_interval}s)")
                return  # è¿˜æ²¡åˆ°æ¸…ç†æ—¶é—´
            
            self.last_env_cleanup_time = current_time
            
            from env_k8s import RemoteDesktopEnv
            from datetime import datetime, timezone, timedelta
            
            # è·å–æ‰€æœ‰ç¯å¢ƒåˆ—è¡¨
            try:
                all_envs = RemoteDesktopEnv.list_environments(
                    runner_cfg.env.server_url, 
                    runner_cfg.env.user_token
                )
                logger.info(f"ç¯å¢ƒæ¸…ç†æ£€æŸ¥ - å‘ç° {len(all_envs)} ä¸ªç¯å¢ƒ")
            except Exception as e:
                logger.error(f"è·å–ç¯å¢ƒåˆ—è¡¨å¤±è´¥: {e}")
                return
            
            if not all_envs:
                logger.debug("ç¯å¢ƒæ¸…ç†æ£€æŸ¥ - æ²¡æœ‰å‘ç°ä»»ä½•ç¯å¢ƒ")
                return
            
            # ç»Ÿè®¡ä¿¡æ¯
            cleanup_stats = {
                'total_envs': len(all_envs),
                'active_envs': len(self.active_service_ids),
                'orphaned_envs': 0,
                'timeout_envs': 0,
                'cleaned_envs': 0,
                'failed_cleanups': 0
            }
            
            logger.info(f"ç¯å¢ƒæ¸…ç†æ£€æŸ¥å¼€å§‹ - æ€»ç¯å¢ƒæ•°: {cleanup_stats['total_envs']}, æ´»è·ƒç¯å¢ƒæ•°: {cleanup_stats['active_envs']}")
            
            for env in all_envs:
                server_id = env.get('server_id') or env.get('service_id')
                created_at_str = env.get('created_at', '')
                
                if not server_id:
                    logger.warning(f"ç¯å¢ƒç¼ºå°‘server_id/service_id: {env}")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ´»è·ƒåˆ—è¡¨ä¸­
                if server_id in self.active_service_ids:
                    logger.debug(f"ç¯å¢ƒ {server_id} åœ¨æ´»è·ƒåˆ—è¡¨ä¸­ï¼Œè·³è¿‡")
                    continue
                
                cleanup_stats['orphaned_envs'] += 1
                
                # æ‰“å°å­¤ç«‹ç¯å¢ƒçš„è¯¦ç»†ä¿¡æ¯
                logger.warning(f"ğŸ” å‘ç°å­¤ç«‹ç¯å¢ƒ - Server ID: {server_id}, åˆ›å»ºæ—¶é—´: {created_at_str}, ç¯å¢ƒä¿¡æ¯: {env}")
                
                # è§£æåˆ›å»ºæ—¶é—´ - æ ¼å¼: "2025-08-09T14:30:19"
                try:
                    if created_at_str:
                        created_at = datetime.fromisoformat(created_at_str)
                        if not created_at:
                            logger.warning(f"ç¯å¢ƒ {server_id} æ—¶é—´æ ¼å¼æ— æ³•è§£æ: {created_at_str}")
                            continue
                        
                        # è®¡ç®—å­˜åœ¨æ—¶é—´ (æœåŠ¡å™¨è¿”å›åŒ—äº¬æ—¶é—´ï¼Œæœ¬åœ°ä¹Ÿä½¿ç”¨åŒ—äº¬æ—¶é—´)
                        now = datetime.now()  # æœ¬åœ°æ—¶é—´(åŒ—äº¬æ—¶é—´)
                        age_seconds = (now - created_at).total_seconds()
                        if age_seconds > 50:
                           logger.info(f"å­¤å„¿ç¯å¢ƒæˆ–è€…ç¯å¢ƒæ²¡åˆ›å»ºå®Œæˆï¼š {server_id} æ—¶é—´è®¡ç®— - å½“å‰æ—¶é—´: {now}, åˆ›å»ºæ—¶é—´: {created_at}, å­˜åœ¨ç§’æ•°: {age_seconds:.1f}ç§’")
                        
                        # å°†ç§’è½¬æ¢ä¸ºæ›´æ˜“è¯»çš„æ ¼å¼
                        if age_seconds < 0:
                            logger.warning(f"ç¯å¢ƒ {server_id} - æ—¶é—´è®¡ç®—å¼‚å¸¸ï¼åˆ›å»ºæ—¶é—´: {created_at_str} ({created_at}), å½“å‰æ—¶é—´: {now}, æ—¶é—´å·®: {age_seconds:.1f}ç§’")
                        else:
                            hours = int(age_seconds // 3600)
                            minutes = int((age_seconds % 3600) // 60)
                            seconds = int(age_seconds % 60)
                            time_str = f"{hours}h{minutes}m{seconds}s" if hours > 0 else f"{minutes}m{seconds}s"
                            logger.info(f"ç¯å¢ƒ {server_id} - åˆ›å»ºæ—¶é—´: {created_at_str}, å­˜åœ¨æ—¶é•¿: {time_str} ({age_seconds:.1f}ç§’)")
                        
                        # å¦‚æœè¶…è¿‡è¶…æ—¶æ—¶é—´ï¼Œåˆ™åˆ é™¤
                        if age_seconds > self.env_cleanup_timeout:
                            cleanup_stats['timeout_envs'] += 1
                            logger.warning(f"â° å‘ç°è¶…æ—¶ç¯å¢ƒ {server_id}: åˆ›å»ºæ—¶é—´ {created_at_str}, å­˜åœ¨æ—¶é•¿ {time_str} ({age_seconds:.1f}ç§’) > é˜ˆå€¼ {self.env_cleanup_timeout}ç§’ï¼Œå‡†å¤‡åˆ é™¤")
                            
                            # æ‰§è¡Œåˆ é™¤
                            try:
                                from env_k8s import release_single_env
                                success = release_single_env(
                                    runner_cfg.env.server_url, 
                                    runner_cfg.env.user_token, 
                                    server_id
                                )
                                if success:
                                    cleanup_stats['cleaned_envs'] += 1
                                    
                                    # ä»æ´»è·ƒç¯å¢ƒé›†åˆä¸­ç§»é™¤ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                                    if server_id in self.active_service_ids:
                                        self.active_service_ids.discard(server_id)
                                        logger.info(f"âœ… æˆåŠŸåˆ é™¤è¶…æ—¶ç¯å¢ƒ: {server_id}ï¼Œå·²ä»æ´»è·ƒç¯å¢ƒåˆ—è¡¨ç§»é™¤")
                                    else:
                                        logger.info(f"âœ… æˆåŠŸåˆ é™¤è¶…æ—¶ç¯å¢ƒ: {server_id}ï¼ˆè¯¥ç¯å¢ƒä¸åœ¨æ´»è·ƒåˆ—è¡¨ä¸­ï¼‰")
                                    
                                    # æ£€æŸ¥å¹¶æ¸…ç†task_to_service_mapä¸­çš„ç›¸å…³æ˜ å°„
                                    removed_tasks = []
                                    for task_ref, service_id in list(self.task_to_service_map.items()):
                                        if service_id == server_id:
                                            removed_tasks.append(task_ref)
                                            del self.task_to_service_map[task_ref]
                                    
                                    if removed_tasks:
                                        logger.info(f"ä»task_to_service_mapä¸­æ¸…ç†äº† {len(removed_tasks)} ä¸ªç›¸å…³ä»»åŠ¡æ˜ å°„")
                                        
                                else:
                                    cleanup_stats['failed_cleanups'] += 1
                                    logger.error(f"âŒ åˆ é™¤è¶…æ—¶ç¯å¢ƒå¤±è´¥: {server_id}")
                            except Exception as e:
                                cleanup_stats['failed_cleanups'] += 1
                                logger.error(f"åˆ é™¤è¶…æ—¶ç¯å¢ƒå¼‚å¸¸: {server_id}, é”™è¯¯: {e}")
                        else:
                            logger.debug(f"ç¯å¢ƒ {server_id} æœªè¶…æ—¶ - å­˜åœ¨æ—¶é•¿: {age_seconds:.1f}ç§’ < {self.env_cleanup_timeout}ç§’")
                    else:
                        logger.warning(f"ç¯å¢ƒ {server_id} ç¼ºå°‘created_atå­—æ®µï¼Œè·³è¿‡æ—¶é—´æ£€æŸ¥")
                        
                except Exception as e:
                    logger.error(f"è§£æç¯å¢ƒ {server_id} åˆ›å»ºæ—¶é—´å¤±è´¥: {created_at_str}, é”™è¯¯: {e}")
            
            # è®°å½•æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
            logger.info(f"ç¯å¢ƒæ¸…ç†æ£€æŸ¥å®Œæˆ - "
                       f"æ€»ç¯å¢ƒ: {cleanup_stats['total_envs']}, "
                       f"æ´»è·ƒç¯å¢ƒ: {cleanup_stats['active_envs']}, "
                       f"å­¤ç«‹ç¯å¢ƒ: {cleanup_stats['orphaned_envs']}, "
                       f"è¶…æ—¶ç¯å¢ƒ: {cleanup_stats['timeout_envs']}, "
                       f"å·²æ¸…ç†: {cleanup_stats['cleaned_envs']}, "
                       f"æ¸…ç†fail: {cleanup_stats['failed_cleanups']}")
                       
        except Exception as e:
            logger.error(f"ç¯å¢ƒæ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        
        logger.info("ç¯å¢ƒæ¸…ç†æ£€æŸ¥å®Œæˆ")
    
    def _update_active_service_ids(self):
        """æ›´æ–°æ´»è·ƒçš„service_idåˆ—è¡¨"""
        # è¿™ä¸ªæ–¹æ³•éœ€è¦ä»æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡ä¸­æå–service_id
        # ç”±äºæˆ‘ä»¬æ— æ³•ç›´æ¥ä»Rayå¯¹è±¡å¼•ç”¨ä¸­è·å–service_idï¼Œ
        # æˆ‘ä»¬éœ€è¦åœ¨ä»»åŠ¡å¯åŠ¨æ—¶è®°å½•ï¼Œåœ¨ä»»åŠ¡å®Œæˆæ—¶ç§»é™¤
        pass

    async def start_rollout(self, task_loader, runner_cfg, model_pool, storage, mysql_writer):
        """ä¸»å¾ªç¯ï¼šæŒç»­å¤„ç†ä»»åŠ¡"""
        # ç¡®ä¿å¼‚å¸¸å¤„ç†å™¨å·²è®¾ç½®ï¼ˆç°åœ¨event loopå·²ç»è¿è¡Œï¼‰
        try:
            loop = asyncio.get_running_loop()
            if not hasattr(loop, '_exception_handler') or loop._exception_handler is None:
                self._setup_exception_handler()
        except Exception as e:
            logger.warning(f"é‡æ–°è®¾ç½®å¼‚å¸¸å¤„ç†å™¨å¤±è´¥: {e}")
            
        logger.info("å¼€å§‹ä»»åŠ¡å¤„ç†å¾ªç¯")
    
        
        while True:
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¼˜é›…é€€å‡º
                if self.should_graceful_exit:
                    logger.info(f"æ£€æµ‹åˆ°ä¼˜é›…é€€å‡ºä¿¡å·: {self.exit_reason}")
                    if self.active_tasks:
                        logger.info(f"ç­‰å¾… {len(self.active_tasks)} ä¸ªæ´»è·ƒä»»åŠ¡å®Œæˆ...")
                        # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
                        try:
                            await asyncio.wait(self.active_tasks, timeout=60.0)  # æœ€å¤šç­‰å¾…60ç§’
                        except asyncio.TimeoutError:
                            logger.warning("ç­‰å¾…ä»»åŠ¡å®Œæˆè¶…æ—¶ï¼Œå¼ºåˆ¶é€€å‡º")
                    logger.info("ä¼˜é›…é€€å‡ºå®Œæˆ")
                    break
                
                # 0.å®šæœŸæ¸…ç†å­¤ç«‹çš„ç¯å¢ƒ
                # logger.info("å‡†å¤‡è°ƒç”¨ _cleanup_orphaned_environments æ–¹æ³•")
                # await self._cleanup_orphaned_environments(runner_cfg)
                # logger.info("_cleanup_orphaned_environments æ–¹æ³•è°ƒç”¨å®Œæˆ")
                
                # 1. å¡«å……ä»»åŠ¡é˜Ÿåˆ—ï¼ˆæœ€å¤šå¡«å……MAX_TASK_QUEUE_SIZEæ¬¡ï¼‰
                if (self.task_queue.empty() and 
                    self.poll_count < self.max_task_queue_size and
                    not self.should_graceful_exit):  # ä¸åœ¨é€€å‡ºçŠ¶æ€æ—¶æ‰å¡«å……ä»»åŠ¡

                    new_tasks_batch = task_loader.poll_for_tasks()
                    logger.info(f"è·å–åˆ°æ–°ä»»åŠ¡æ‰¹æ¬¡ï¼Œå¤§å°: {len(new_tasks_batch)}")
                    if new_tasks_batch:
                        self.poll_count += 1  # å¢åŠ å¡«å……æ¬¡æ•°
                        added_count = 0
                        
                        # å…ˆæŒ‰æˆåŠŸç‡æ’åºä»»åŠ¡
                        # if self.dynamic_rollout:
                        #     sorted_tasks = task_loader.sort_tasks_by_success_rate(new_tasks_batch)
                        # else:   
                        sorted_tasks = new_tasks_batch
                                                
                        for task in sorted_tasks:
                            task_id = task.get('task_config', {}).get('raw', {}).get('task_id', 'unknown') # debug liuyang
                            
                            if self.dynamic_rollout:
                                # è·å–åŠ¨æ€ rollout_n å€¼
                                traj_counts, success_rate, dynamic_rollout_n = task_loader.get_dynamic_rollout_n(task_id, self.rollout_n) # æˆåŠŸç‡é«˜äºé˜ˆå€¼çš„taskä¹Ÿä¼šé‡‡æ ·ï¼Œå®æ—¶ç›‘æµ‹ï¼Œä¸€æ—¦æˆåŠŸç‡ä½äºé˜ˆå€¼ï¼Œä¼šé‡æ–°é‡‡æ ·self.rollout_næ¡è½¨è¿¹
                            else:
                                dynamic_rollout_n = self.rollout_n
                            # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»º dynamic_rollout_n ä¸ªå‰¯æœ¬
                            for rollout_idx in range(dynamic_rollout_n):
                                task_with_trace = copy.deepcopy(task)
                                trace_id = self._generate_trace_id()
                                task_with_trace['trace_id'] = trace_id
                                task_with_trace['rollout_idx'] = rollout_idx  # æ·»åŠ rolloutç´¢å¼•
                                task_with_trace['dynamic_rollout_n'] = dynamic_rollout_n  # æ·»åŠ åŠ¨æ€rollout_nä¿¡æ¯
                                
                                await self.task_queue.put(task_with_trace)
                                added_count += 1
                                
                                logger.info(f"[{trace_id}] æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ— - task_id: {task_id}, rollout_idx: {rollout_idx + 1}/{dynamic_rollout_n}")
                        logger.info(f"ç¬¬ {self.poll_count} æ¬¡å¡«å……ä»»åŠ¡å®Œæˆï¼Œæ·»åŠ äº† {added_count} ä¸ªä»»åŠ¡ï¼Œå½“å‰é˜Ÿåˆ—å¤§å°: {self.task_queue.qsize()}")
                    else:
                        # æ²¡æœ‰æ–°ä»»åŠ¡ä½†æœªè¾¾åˆ°å¡«å……æ¬¡æ•°é™åˆ¶ï¼Œç­‰å¾…ä¸€ä¸‹å†è¯•
                        if self.poll_count < self.max_task_queue_size:
                            await asyncio.sleep(1)
                            continue

                # 2. å¯åŠ¨ä»»åŠ¡ï¼ˆä¸è¶…è¿‡æœ€å¤§å¹¶è¡Œæ•°ï¼‰
                started_count = 0
                while (len(self.active_tasks) < self.max_concurrent_envs and 
                       not self.task_queue.empty() and
                       not self.should_graceful_exit):  # ä¸åœ¨é€€å‡ºçŠ¶æ€æ—¶æ‰å¯åŠ¨æ–°ä»»åŠ¡

                    try:
                        task_info = await asyncio.wait_for(self.task_queue.get(), timeout=0.1)
                        trace_id = task_info.get('trace_id', 'unknown_trace')
                        task_id = task_info.get('task_config', {}).get('raw', {}).get('task_id', 'unknown')
                        rollout_idx = task_info.get('rollout_idx', 0)
                        dynamic_rollout_n = task_info.get('dynamic_rollout_n', self.rollout_n)
                            
                        logger.info(f"[{trace_id}] å¼€å§‹å¯åŠ¨ä»»åŠ¡ - task_id: {task_id}, rollout_idx: {rollout_idx + 1}/{dynamic_rollout_n}")
                            
                        try:
                            actor = TrajectoryRunnerActor.options(num_cpus=0.5).remote(task_info, runner_cfg)
                            task_ref = actor.run_episode.remote(model_pool, storage, mysql_writer)
                            self.active_tasks.add(task_ref)
                            self.task_trace_map[task_ref] = trace_id
                            self.task_to_actor_map[task_ref] = actor  # ä¿å­˜Actorå¼•ç”¨
                            
                            # å¼‚æ­¥è·Ÿè¸ªä»»åŠ¡å®Œæˆå’Œservice_idç®¡ç†
                            task_completion = asyncio.create_task(self._track_task_completion(task_ref, task_id, trace_id, rollout_idx))
                            # åå»service_id
                            asyncio.create_task(self._track_service_id(task_ref, actor))
                            # åªä¸ºtask_completionæ·»åŠ å¼‚å¸¸å¤„ç†å›è°ƒï¼Œé¿å…é‡å¤å¤„ç†
                            task_completion.add_done_callback(self._handle_task_exception)
                           
                            self.stats['total_started'] += 1
                            started_count += 1
                            logger.info(f"[{trace_id}] ä»»åŠ¡å¯åŠ¨æˆåŠŸ - task_id: {task_id}, rollout_idx: {rollout_idx + 1}/{dynamic_rollout_n}, å½“å‰æ´»è·ƒä»»åŠ¡æ•°: {len(self.active_tasks)}")
                        except ray.exceptions.RayTaskError as e:
                            logger.warning(f"[{trace_id}] Rayä»»åŠ¡åˆ›å»ºå¤±è´¥: {e}")
                        except Exception as e:
                            logger.error(f"[{trace_id}] å¯åŠ¨ä»»åŠ¡å¤±è´¥ - task_id: {task_id}, rollout_idx: {rollout_idx + 1}/{dynamic_rollout_n}, é”™è¯¯: {e}")
                            
                    except asyncio.TimeoutError:
                        break  # é˜Ÿåˆ—ä¸ºç©ºï¼Œè·³å‡ºå¾ªç¯
                
                if started_count > 0:
                    logger.info(f"æœ¬è½®å¯åŠ¨äº† {started_count} ä¸ªä»»åŠ¡")

                # 3. ç­‰å¾…ä»»åŠ¡å®Œæˆï¼ˆä½¿ç”¨æ›´é«˜æ•ˆçš„æ–¹å¼ï¼‰
                if self.active_tasks:
                    # ç­‰å¾…è‡³å°‘ä¸€ä¸ªä»»åŠ¡å®Œæˆï¼Œæˆ–è€…è¶…æ—¶
                    try:
                        done, pending = await asyncio.wait(
                            self.active_tasks, 
                            return_when=asyncio.FIRST_COMPLETED,
                            timeout=1.0  # 1ç§’è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
                        )
                        
                        # å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡
                        for task_ref in done:
                            # æ³¨æ„ï¼šä¸è¦åœ¨è¿™é‡Œæ¸…ç†ï¼Œè®©_track_task_completionæ¥å¤„ç†
                            # è¿™æ ·å¯ä»¥ç¡®ä¿service_idç­‰èµ„æºå¾—åˆ°æ­£ç¡®æ¸…ç†
                            pass
                            
                    except asyncio.TimeoutError:
                        # è¶…æ—¶æ˜¯æ­£å¸¸çš„ï¼Œç»§ç»­å¾ªç¯
                        pass
                else:
                    # æ²¡æœ‰æ´»è·ƒä»»åŠ¡æ—¶æ£€æŸ¥æ˜¯å¦å·²å®Œæˆæ‰€æœ‰å·¥ä½œæˆ–éœ€è¦ä¼˜é›…é€€å‡º
                    if self.should_graceful_exit:
                        logger.info("ä¼˜é›…é€€å‡ºæµç¨‹å®Œæˆï¼Œæ‰€æœ‰ä»»åŠ¡å·²æ¸…ç†")
                        break
                    elif (self.task_queue.empty() and 
                          self.poll_count >= self.max_task_queue_size):
                        logger.info("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œå‡†å¤‡é€€å‡º")
                        break
                    
                    await asyncio.sleep(0.1)
                    
                # å®šæœŸæ‰“å°ç»Ÿè®¡ä¿¡æ¯
                if self.stats['total_started'] % 10 == 0 and self.stats['total_started'] > 0:
                    self._log_stats()
                    
            except Exception as e:
                logger.error(f"ä¸»å¾ªç¯å‘ç”Ÿé”™è¯¯: {e}")
                # ä¸¥é‡é”™è¯¯æ—¶é€€å‡ºå¾ªç¯
                logger.error("å‘ç”Ÿä¸¥é‡é”™è¯¯ï¼Œç»“æŸä»»åŠ¡å¤„ç†")
                break
        
        # ä¸»å¾ªç¯ç»“æŸï¼Œæ‰“å°æœ€ç»ˆç»Ÿè®¡
        self._log_stats()
        logger.info("ä»»åŠ¡å¤„ç†å¾ªç¯ç»“æŸ")
        return True  # è¿”å›å®ŒæˆçŠ¶æ€

    async def _track_task_completion(self, task_ref: ray.ObjectRef, task_id: str, trace_id: str, rollout_idx: int):
        """è·Ÿè¸ªä»»åŠ¡å®ŒæˆçŠ¶æ€"""
        try:
            start_time = time.time()
            task_failed = False  # æ ‡è®°ä»»åŠ¡æ˜¯å¦å¤±è´¥
            
            try:
                result = await task_ref
                duration = time.time() - start_time
                self.stats['total_completed'] += 1
                logger.info(f"[{trace_id}] ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ - task_id: {task_id}, rollout_idx: {rollout_idx + 1}/{self.rollout_n}, è€—æ—¶: {duration:.2f}ç§’")
                
            except ResourceExhaustedException as e:
                # æ£€æµ‹åˆ°èµ„æºè€—å°½å¼‚å¸¸ï¼Œè®¾ç½®ä¼˜é›…é€€å‡ºæ ‡å¿—
                task_failed = True
                duration = time.time() - start_time
                self.stats['total_failed'] += 1
                self.should_graceful_exit = True
                self.exit_reason = f"ç¯å¢ƒæœåŠ¡å™¨èµ„æºå·²è¾¾ä¸Šé™"
                logger.error(f"[{trace_id}] æ£€æµ‹åˆ°èµ„æºè€—å°½å¼‚å¸¸ï¼Œå¯åŠ¨ä¼˜é›…é€€å‡ºæµç¨‹ - task_id: {task_id}, è€—æ—¶: {duration:.2f}ç§’, é”™è¯¯: {e}")
                
            except BaseException as e:
                # å¤„ç†æ‰€æœ‰å…¶ä»–å¼‚å¸¸ï¼ˆåŒ…æ‹¬ Exception å’Œç³»ç»Ÿçº§å¼‚å¸¸å¦‚ KeyboardInterruptï¼‰
                task_failed = True
                duration = time.time() - start_time
                if isinstance(e, Exception):
                    self.stats['total_failed'] += 1
                    # æ˜¾ç¤ºé”™è¯¯ç±»å‹å’Œç®€è¦ä¿¡æ¯ï¼Œä½†ä¸æ˜¾ç¤ºå®Œæ•´å †æ ˆ
                    error_type = type(e).__name__
                    error_msg = str(e)  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦
                    logger.error(f"[{trace_id}] ä»»åŠ¡æ‰§è¡Œå¤±è´¥ - task_id: {task_id}, rollout_idx: {rollout_idx + 1}/{self.rollout_n}, è€—æ—¶: {duration:.2f}ç§’, é”™è¯¯: {error_type}: {error_msg}")
                    logger.info(f"[{trace_id}] å®Œæ•´å¼‚å¸¸è¯¦æƒ…: {e}")
                    
                    # å¼ºåˆ¶ç»ˆæ­¢å¤±è´¥çš„Actorä»¥é˜²æ­¢æ— é™å¾ªç¯
                    actor = self.task_to_actor_map.get(task_ref)
                    if actor:
                        try:
                            ray.kill(actor)
                            logger.info(f"[{trace_id}] å·²å¼ºåˆ¶ç»ˆæ­¢å¤±è´¥çš„Actor")
                        except Exception as kill_error:
                            logger.warning(f"[{trace_id}] ç»ˆæ­¢Actorå¤±è´¥: {kill_error}")
                else:
                    logger.error(f"[{trace_id}] ä»»åŠ¡è¢«ç³»ç»Ÿçº§å¼‚å¸¸ä¸­æ–­ - task_id: {task_id}, è€—æ—¶: {duration:.2f}ç§’, é”™è¯¯: {e}")
            
            finally:
                try:
                    # 1. èµ„æºæ¸…ç†ï¼šä»æ´»è·ƒä»»åŠ¡é›†åˆä¸­ç§»é™¤
                    self.active_tasks.discard(task_ref)
                    self.task_trace_map.pop(task_ref, None)
                    self.task_to_actor_map.pop(task_ref, None)  # æ¸…ç†Actorå¼•ç”¨
                    
                    # ä»æ´»è·ƒservice_idåˆ—è¡¨ä¸­ç§»é™¤
                    service_id = self.task_to_service_map.pop(task_ref, None)
                    if service_id:
                        self.active_service_ids.discard(service_id)
                        logger.info(f"[{trace_id}] ä»æ´»è·ƒç¯å¢ƒåˆ—è¡¨ä¸­ç§»é™¤ service_id: {service_id}")
                    
                    logger.info(f"[{trace_id}] ä»»åŠ¡èµ„æºæ¸…ç†å®Œæˆï¼Œå½“å‰æ´»è·ƒä»»åŠ¡æ•°: {len(self.active_tasks)}")
                        
                except Exception as cleanup_error:
                    logger.error(f"[{trace_id}] ä»»åŠ¡æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {cleanup_error}")
                    
        except Exception as outer_error:
            logger.error(f"[{trace_id}] _track_task_completionæ–¹æ³•å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {outer_error}")
            import traceback
            logger.error(f"[{trace_id}] é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
        
        except BaseException as system_error:
            logger.error(f"[{trace_id}] _track_task_completionæ–¹æ³•è¢«ç³»ç»Ÿçº§å¼‚å¸¸ä¸­æ–­: {system_error}")
        
        # æ³¨æ„ï¼šèµ„æºæ¸…ç†å·²åœ¨å†…å±‚finallyå—ä¸­å¤„ç†
    

    async def _track_service_id(self, task_ref: ray.ObjectRef, actor):
        """è·Ÿè¸ªä»»åŠ¡çš„service_id"""
        try:
            # ç­‰å¾…ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼ˆä½¿ç”¨äº‹ä»¶æœºåˆ¶ï¼Œæœ€å¤§ç­‰å¾…180ç§’ï¼‰
          # ç­‰å¾…ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼ˆé€šè¿‡æ˜¾å¼å®šä¹‰çš„è¿œç¨‹æ–¹æ³•ï¼‰
            env_ready = await actor.wait_for_env_ready.remote(timeout=180.0)
            if not env_ready:
                logger.warning("ä»»åŠ¡ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥æˆ–è¶…æ—¶ - å¯èƒ½æ˜¯èµ„æºä¸è¶³æˆ–æœåŠ¡å™¨é”™è¯¯")
                return
            
            # å°è¯•è·å–service_id
            service_id = await actor.get_service_id.remote()
            if service_id:
                self.task_to_service_map[task_ref] = service_id
                self.active_service_ids.add(service_id)
                logger.info(f"è·Ÿè¸ªåˆ°ä»»åŠ¡ç¯å¢ƒ service_id: {service_id}")
            else:
                # service_idä¸ºNoneé€šå¸¸æ„å‘³ç€ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼ˆå¦‚èµ„æºä¸è¶³ï¼‰
                logger.warning("æ— æ³•è·å–ä»»åŠ¡çš„service_id - å¯èƒ½æ˜¯ç¯å¢ƒåˆå§‹åŒ–å¤±è´¥ï¼ˆèµ„æºä¸è¶³æˆ–æœåŠ¡å™¨é”™è¯¯ï¼‰")
                
        except BaseException as e:
            # å¤„ç†æ‰€æœ‰å¼‚å¸¸ï¼ˆåŒ…æ‹¬ Exception å’Œç³»ç»Ÿçº§å¼‚å¸¸ï¼‰
            if isinstance(e, Exception):
                logger.warning(f"è·å–ä»»åŠ¡service_idå¤±è´¥: {e}")
            else:
                logger.error(f"è·å–service_idè¿‡ç¨‹è¢«ç³»ç»Ÿçº§å¼‚å¸¸ä¸­æ–­: {e}")
    
    def _handle_task_exception(self, task):
        """å¤„ç†å¼‚æ­¥ä»»åŠ¡çš„å¼‚å¸¸"""
        try:
            if task.exception() is not None:
                exception = task.exception()
                # æ ¹æ®å¼‚å¸¸ç±»å‹è°ƒæ•´æ—¥å¿—çº§åˆ«ï¼Œå¹¶ä¸”å‡å°‘é‡å¤æ—¥å¿—
                if "RayTaskError" in str(type(exception)) or "Failed to get screenshot" in str(exception):
                    # Rayä»»åŠ¡å¤±è´¥æ˜¯é¢„æœŸçš„ï¼Œåªè®°å½•ä¸€æ¬¡ç®€çŸ­ä¿¡æ¯
                    logger.error(f"Rayä»»åŠ¡å¤±è´¥ï¼ˆé¢„æœŸè¡Œä¸ºï¼‰: {type(exception).__name__}")
                else:
                    # å…¶ä»–å¼‚å¸¸ä½¿ç”¨ERRORçº§åˆ«
                    logger.error(f"å¼‚æ­¥ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {exception}")
            else:
                # ä»»åŠ¡æ­£å¸¸å®Œæˆ
                logger.debug("å¼‚æ­¥ä»»åŠ¡æ­£å¸¸å®Œæˆ")
                            
        except Exception as e:
            logger.error(f"å¤„ç†å¼‚æ­¥ä»»åŠ¡å¼‚å¸¸æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            
    def _log_stats(self):
        """è®°å½•ç»Ÿè®¡ä¿¡æ¯"""
        runtime = time.time() - self.stats['start_time']
        success_rate = self.stats['total_completed']/max(1, self.stats['total_completed'] + self.stats['total_failed'])*100
        
        logger.info(f"=== ä»»åŠ¡ç»Ÿè®¡ === è¿è¡Œæ—¶é—´: {runtime:.1f}ç§’, "
                   f"å·²å¯åŠ¨: {self.stats['total_started']}, "
                   f"å·²å®Œæˆ: {self.stats['total_completed']}, "
                   f"fail: {self.stats['total_failed']}, "
                   f"å½“å‰æ´»è·ƒ: {len(self.active_tasks)}, "
                   f"é˜Ÿåˆ—å¤§å°: {self.task_queue.qsize()}, "
                   f"å·²å¡«å……æ¬¡æ•°: {self.poll_count}/{self.max_task_queue_size}, "
                   f"æˆåŠŸç‡: {success_rate:.1f}%")
        

    async def shutdown(self):
        """ä¼˜é›…å…³é—­åè°ƒå™¨"""
        logger.info("æ­£åœ¨å…³é—­AgentCoordinator...")
        
        # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
        if self.active_tasks:
            active_traces = [self.task_trace_map.get(task_ref, 'unknown') for task_ref in self.active_tasks]
            logger.info(f"ç­‰å¾… {len(self.active_tasks)} ä¸ªæ´»è·ƒä»»åŠ¡å®Œæˆï¼Œtrace_ids: {active_traces}")
            await asyncio.wait(self.active_tasks, timeout=30.0)  # 30ç§’è¶…æ—¶
            
        self._log_stats()
        logger.info("AgentCoordinatorå·²å…³é—­")

